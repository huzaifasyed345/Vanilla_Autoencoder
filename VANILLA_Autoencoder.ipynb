{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pk3K3jSX0SX0"
      },
      "outputs": [],
      "source": [
        "#@markdown #**IMPORTING NECESSARY LIBRARIES**\n",
        "###1. Load Data and Splot Data\n",
        "\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##**Spliting the data into x_train, y_train, x_test and y_test**\n",
        "# splitting the data into test and train set\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n"
      ],
      "metadata": {
        "id": "GNwpULHU0tL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##**Displaying the sample images from x_train**\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Number of digits to display\n",
        "n = 10\n",
        "\n",
        "# Create a figure to display the images\n",
        "plt.figure(figsize=(20, 4))\n",
        "\n",
        "# Loop through the first 'n' images\n",
        "for i in range(n):\n",
        "    # Create a subplot within the figure\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "\n",
        "    # Display the original image\n",
        "    plt.imshow(X_test[i].reshape(28, 28))\n",
        "\n",
        "    # Set colormap to grayscale\n",
        "    plt.gray()\n",
        "\n",
        "    # Hide x-axis and y-axis labels and ticks\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "# Show the figure with the images\n",
        "plt.show()\n",
        "\n",
        "# Close the figure\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "Q0R-u7WH05Gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##**Displaying the shape of x_train and X_test**\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "p4gPCDGu08y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##**Reshaping the images from 28,28,1 -dimension vector**\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), 28*28*1))\n",
        "x_test = x_test.reshape((len(x_test), 28*28*1))\n",
        "print (x_train.shape)\n",
        "print (x_test.shape)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5nA6HB191CVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #@markdown #**IMPORTING LIBRARIES FOR CNN**\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EDN7Rt2N1Et1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #@markdown #STRUCTURE OF AUTOENCODER\n",
        "\n",
        "input_layer_cnv = Input(shape = (28,28,1))\n",
        "ae_cnv_en = Conv2D (32, (3,3), activation = \"relu\", padding = \"same\", kernel_initializer=\"he_normal\")(input_layer_cnv)\n",
        "ae_cnv_en = MaxPooling2D ((2,2), padding=\"same\")(ae_cnv_en)\n",
        "\n",
        "ae_cnv_en = Conv2D (32, (3,3), activation = \"relu\", padding = \"same\")(ae_cnv_en)\n",
        "ae_cnv_en = MaxPooling2D ((2,2), padding=\"same\")(ae_cnv_en)\n",
        "\n",
        "ae_cnv_en = Conv2D (4, (3,3), activation = \"relu\", padding = \"same\")(ae_cnv_en)\n",
        "ae_cnv_en = MaxPooling2D ((2,2), padding=\"same\")(ae_cnv_en)\n",
        "\n",
        "ae_cnv_en = Flatten(name = \"bot\")(ae_cnv_en)\n",
        "\n",
        "ae_cnv_de = Reshape((4,4,4), input_shape= (64,), name= \"botnext0\")(ae_cnv_en)\n",
        "ae_cnv_de = Conv2D (4, (3,3), activation = \"relu\", padding = \"same\",name= \"botnext1\")(ae_cnv_de)\n",
        "ae_cnv_de = UpSampling2D ((2,2),name= \"botnext2\")(ae_cnv_de)\n",
        "\n",
        "ae_cnv_de = Conv2D (32, (3,3), activation = \"relu\", padding = \"same\", name= \"botnext3\")(ae_cnv_de)\n",
        "ae_cnv_de = UpSampling2D ((2,2), name= \"botnext4\")(ae_cnv_de)\n",
        "\n",
        "ae_cnv_de = Conv2D (32, (3,3), activation = \"relu\", padding = \"valid\",name= \"botnext5\")(ae_cnv_de)\n",
        "ae_cnv_de = UpSampling2D ((2,2), name= \"botnext6\")(ae_cnv_de)\n",
        "\n",
        "ae_cnv_de = Conv2D (1, (3,3), activation = \"sigmoid\", padding = \"same\",name = \"botnext7\")(ae_cnv_de)\n",
        "Ae_Conv = Model(inputs = input_layer_cnv, outputs = ae_cnv_de)\n",
        "\n",
        "Ae_Conv.compile(optimizer=tf.keras.optimizers.SGD(0.09,clipvalue=2.5), loss='binary_crossentropy', metrics = [\"accuracy\"])\n",
        "# Ae_Conv.compile(optimizer=tf.keras.optimizers.Adadelta(0.1,clipvalue=2), loss='binary_crossentropy', metrics = [\"accuracy\"])\n",
        "Ae_Conv.summary()\n",
        "\n",
        "# Adam(learning_rate=0.001)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Oi_4vZoF1QFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #ENCODER\n",
        "ae_conv_encoder = Model (inputs = input_layer_cnv, outputs = Ae_Conv.get_layer(\"bot\").output, name = \"Conv_AE_encoder\")\n",
        "ae_conv_encoder.summary()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7SXiffdY1m2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #DECODER\n",
        "# Traversing through the Layers of Decoder using Loop\n",
        "\n",
        "encode_inp_cnv = Input(shape = (64,))\n",
        "tmp_dec = Ae_Conv.get_layer(\"botnext0\")(encode_inp_cnv)\n",
        "for i in range(1,8):\n",
        "  st = \"botnext{}\".format(i)\n",
        "  tmp_dec = Ae_Conv.get_layer(st)(tmp_dec)\n",
        "\n",
        "ae_conv_decoder = Model(inputs = encode_inp_cnv, outputs = tmp_dec, name= \"Conv_AE_decoder\")\n",
        "ae_conv_decoder.summary()\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "d3nCq3LM1slj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #RESHAPE the images from -dimension vector TO 28,28,1\n",
        "x_train = x_train.reshape(x_train.shape[0], 28,28,1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28,28,1)\n",
        "print(x_train.shape, x_test.shape)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7SRg_EK21ykA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #TRAINING MODEL\n",
        "from time import time\n",
        "tic = time()\n",
        "Ae_Conv.fit(x_train, x_train,\n",
        "                epochs=200,\n",
        "                verbose=2,\n",
        "                batch_size=128,\n",
        "                shuffle=False, validation_split = 0.1)\n",
        "                #validation_data=(x_test, x_test))\n",
        "toc = time()\n",
        "print(\"Training Took {} Secs\".format(toc-tic))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "63dyYGOU2Fuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #TESTING\n",
        "encoded_imgs = ae_conv_encoder.predict(x_test)\n",
        "#encoded_imgs = ae_conv_encoder.predict(x_train[0:100])\n",
        "print (encoded_imgs.shape)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VFaujmbi2hoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #RECONSTRUCTION OF IMAGES VS REAL\n",
        "#decoded_imgs = ae_conv_decoder.predict(encoded_imgs)\n",
        "decoded_imgs = ae_conv_decoder.predict(encoded_imgs)\n",
        "\n",
        "deoceded_images = Ae_Conv.predict(x_test)\n",
        "print(\"Recreated image Representation of Shape {} using Decoder and reduced Image representation of shape {}\".format (decoded_imgs.shape,\n",
        "                                                                                                                      encoded_imgs.shape))\n",
        "n = 15  # how many digits we will display\n",
        "k= 12 # multiplier\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i*k].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i*k].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ShikRHx-2ijM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #RECONSTRUCTION OF IMAGES VS REAL\n",
        "deoceded_images = Ae_Conv.predict(x_test)\n",
        "print(\"Recreated image Representation of Shape {} using Decoder and reduced Image representation of shape {}\".format (deoceded_images.shape,\n",
        "                                                                                                                      deoceded_images.shape))\n",
        "n = 10  # how many digits we will display\n",
        "k= 12 # multiplier\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i*k].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(deoceded_images[i*k].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "a64HVY0m2mM1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}